{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lckWPMSNtmmn"
   },
   "source": [
    "  https://openreview.net/pdf?id=SkZxCk-0Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "x_3L4cW4Ywou"
   },
   "outputs": [],
   "source": [
    "import parser\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HiiMXz-oY7PZ"
   },
   "outputs": [],
   "source": [
    "def read_data(fname):\n",
    "  \"\"\"\n",
    "  Reads the data files.\n",
    "  \"\"\"\n",
    "  with open(fname, 'r') as f:\n",
    "    data = f.read()\n",
    "  data = data.split('\\n')\n",
    "  new_data = []\n",
    "  for d in data[:-1]:\n",
    "#     print('\\r {}'.format(d), end='', flush=True)\n",
    "    a, b, e, _, _, _ = tuple(d.split(','))\n",
    "    new_data.append([a, b, int(e)])\n",
    "  return new_data\n",
    "\n",
    "def batch_data(data, batch_size):\n",
    "  n = len(data)\n",
    "  data = list(zip(*data[0:-1]))  # transpose the data\n",
    "  for i in range(n//batch_size-1):\n",
    "    A = data[0][i*batch_size:(i+1)*batch_size]\n",
    "    B = data[1][i*batch_size:(i+1)*batch_size]\n",
    "    E = data[2][i*batch_size:(i+1)*batch_size]\n",
    "    yield A, B, E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 707,
     "status": "ok",
     "timestamp": 1528060779089,
     "user": {
      "displayName": "Alexander Telfar",
      "photoUrl": "//lh4.googleusercontent.com/-bOBnzCbRWgs/AAAAAAAAAAI/AAAAAAAAABw/Sd6a7MwcUDU/s50-c-k-no/photo.jpg",
      "userId": "112995735588747661471"
     },
     "user_tz": -720
    },
    "id": "bI2KLSu6x3Qt",
    "outputId": "9f81bef4-fcd7-4577-f4c9-548d04220628"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('((m>m)&(((m>m)>(m>m))&((m>m)>(m|m))))',\n",
       "  '~((((m&m)|(m&m))&(m&m)))',\n",
       "  '((m>m)&(((m>m)>(m>m))&((m>m)>(m|m))))',\n",
       "  '~((((m&m)|(m&m))&(m&m)))',\n",
       "  '~((~(m)&~((m&m))))',\n",
       "  '~((m|m))',\n",
       "  '~((~(m)&~((m&m))))',\n",
       "  '~((m|m))',\n",
       "  '(m|(m|m))',\n",
       "  '~((m|(m&(m|m))))'),\n",
       " ('~(~((((m|m)&~(m))|m)))',\n",
       "  '~(((((m>m)&m)&m)|(m|m)))',\n",
       "  '~(((((m>m)&m)&m)|(m|m)))',\n",
       "  '~(~((((m|m)&~(m))|m)))',\n",
       "  '((((m|m)&m)|m)|(~(~((((m|m)>m)&m)))|m))',\n",
       "  '((m|((m>m)>m))>((m&m)&~((m&(m&(m>m))))))',\n",
       "  '((m|((m>m)>m))>((m&m)&~((m&(m&(m>m))))))',\n",
       "  '((((m|m)&m)|m)|(~(~((((m|m)>m)&m)))|m))',\n",
       "  '((m>m)&m)',\n",
       "  '~((m&m))'),\n",
       " (1, 1, 0, 0, 1, 1, 0, 0, 1, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_data('../logical_entailment_dataset/data/train.txt')\n",
    "A, B, E = next(batch_data(data, 10))\n",
    "A, B, E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mETRZKx-eQvz"
   },
   "outputs": [],
   "source": [
    "class Parser():\n",
    "  def __init__(self, language):\n",
    "    self.language = language\n",
    "    self.parser = parser.Parser(language)\n",
    "    self.vocabulary = {op: i for i, op in enumerate(language.symbols)}\n",
    "    \n",
    "  def __call__(self, s):\n",
    "    parse_result = self.parser.parse(s)\n",
    "    ops = [self.vocabulary[op.decode(\"utf-8\")] for op in parse_result.ops]\n",
    "    return ops, parse_result.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 737,
     "status": "ok",
     "timestamp": 1528060782711,
     "user": {
      "displayName": "Alexander Telfar",
      "photoUrl": "//lh4.googleusercontent.com/-bOBnzCbRWgs/AAAAAAAAAAI/AAAAAAAAABw/Sd6a7MwcUDU/s50-c-k-no/photo.jpg",
      "userId": "112995735588747661471"
     },
     "user_tz": -720
    },
    "id": "g9Hf9RzTd2I-",
    "outputId": "6246582c-9a74-45da-ebb8-5f8deabbc9ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([18, 18, 5, 18, 18, 5, 18, 18, 5, 5, 18, 18, 5, 18, 18, 3, 5, 2, 2],\n",
       " [[],\n",
       "  [],\n",
       "  [-2, -1],\n",
       "  [],\n",
       "  [],\n",
       "  [-2, -1],\n",
       "  [],\n",
       "  [],\n",
       "  [-2, -1],\n",
       "  [-4, -1],\n",
       "  [],\n",
       "  [],\n",
       "  [-2, -1],\n",
       "  [],\n",
       "  [],\n",
       "  [-2, -1],\n",
       "  [-4, -1],\n",
       "  [-8, -1],\n",
       "  [-16, -1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_parser = Parser(parser.propositional_language())\n",
    "\n",
    "tree = prop_parser('((m>m)&(((m>m)>(m>m))&((m>m)>(m|m))))')\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cxCd0T8EV0cr"
   },
   "outputs": [],
   "source": [
    "d_world = 30\n",
    "n_worlds=24\n",
    "d_embed = 50\n",
    "batch_size = 10\n",
    "n_ops = len(prop_parser.language.symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4i0p8m_0v6ux"
   },
   "outputs": [],
   "source": [
    "class Sat3Cell():\n",
    "  \"\"\"\n",
    "  Real valued evaluation of satisfiability.\n",
    "  Given a real valued truth assignment, aka the world you are in,\n",
    "  check if it satisfies the given equation.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, d_world, n_ops, d_embed):\n",
    "    num_units = d_embed\n",
    "    self.op_embeddings = tf.get_variable(shape=(n_ops, d_world, num_units), dtype=tf.float32, name='operation_embeddings')\n",
    "    self.W4 = tf.get_variable(shape=(n_ops, 2*d_embed, num_units), dtype=tf.float32, name='W4')\n",
    "    self.b4 = tf.get_variable(shape=(n_ops, num_units), dtype=tf.float32, name='b4')\n",
    "\n",
    "\n",
    "  def __call__(self, w, op, l=None, r=None, scope=None):\n",
    "    \"\"\"    \n",
    "    Args:\n",
    "      w (tf.tensor): [1, d_world]\n",
    "      TODO op (list): \n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO change so __call__ can recieve a batch.\n",
    "    # then bundle all embed/matmul calls\n",
    "    # but op will be varing length. need to stack them!?\n",
    "\n",
    "    \n",
    "    with tf.variable_scope(scope or type(self).__name__):\n",
    "      # nullary ops      \n",
    "      if l is None and r is None:\n",
    "        # look up their embeddings\n",
    "        h = tf.matmul(w, self.op_embeddings[op])\n",
    "        \n",
    "      else:\n",
    "        # unary and binary ops\n",
    "        if l is not None and r is None:\n",
    "          r = tf.zeros_like(l)  # just fake it\n",
    "        \n",
    "        x = tf.concat([l, r], axis=1)\n",
    "        h = tf.matmul(x, self.W4[op]) + self.b4[op]\n",
    "      \n",
    "      return tf.nn.l2_normalize(h, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1646,
     "status": "ok",
     "timestamp": 1528060790466,
     "user": {
      "displayName": "Alexander Telfar",
      "photoUrl": "//lh4.googleusercontent.com/-bOBnzCbRWgs/AAAAAAAAAAI/AAAAAAAAABw/Sd6a7MwcUDU/s50-c-k-no/photo.jpg",
      "userId": "112995735588747661471"
     },
     "user_tz": -720
    },
    "id": "IPF7b7gNvtZx",
    "outputId": "cf448fcb-68e0-447c-83cc-f07485dd08e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50)\n",
      "(1, 50)\n"
     ]
    }
   ],
   "source": [
    "sat3 = Sat3Cell(d_world, n_ops, d_embed)\n",
    "w = tf.random_normal([1, d_world])\n",
    "l = tf.random_normal((1, d_embed))\n",
    "r = tf.random_normal((1, d_embed))\n",
    "\n",
    "h = sat3(w, 0)\n",
    "print(h.shape)\n",
    "\n",
    "h = sat3(w, 12, l, r)\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SXi2C4JLsmOu"
   },
   "outputs": [],
   "source": [
    "class TreeNN():\n",
    "  def __init__(self, cell, parser):\n",
    "    self.cell = cell\n",
    "    self.parser = parser \n",
    "    # !? what about learning to parse the inputs into a tree!?\n",
    "    \n",
    "  def __call__(self, w, s):\n",
    "    \"\"\"\n",
    "    Because each parse will be different!?\n",
    "    \n",
    "    Args:\n",
    "      w: a world\n",
    "      s: a string\n",
    "    \n",
    "    Returns: (1, n)\n",
    "    \"\"\"\n",
    "    # NOTE Can only handle a single element of a batch at a time\n",
    "    \n",
    "    tree = self.parser(s)\n",
    "    return self.apply(tree, [])\n",
    "    \n",
    "    \n",
    "  def apply(self, tree, results, i=0):\n",
    "    \"\"\"\n",
    "    Applies self.cell in a recursive manner.\n",
    "    \n",
    "    Args:\n",
    "      tree (tuple): (ops, args)\n",
    "        ops (list): nodes in depth first order\n",
    "        args (list): the children of ops in depth first order\n",
    "    \"\"\"\n",
    "    ops, args = tree\n",
    "    \n",
    "    # if the current node has children, fetch them from results\n",
    "    l = None\n",
    "    r = None\n",
    "    if len(args[0]) == 1:\n",
    "      l = results[i+args[0][0]]\n",
    "    elif len(args[0]) == 2:\n",
    "      l = results[i+args[0][0]]\n",
    "      r = results[i+args[0][1]]\n",
    "    \n",
    "    if len(tree[1]) == 1:\n",
    "      return self.cell(w, ops[i], l, r)\n",
    "    else:\n",
    "      results.append(self.cell(w, ops[i], l, r))\n",
    "      \n",
    "      tree = (ops, args[1:])\n",
    "      return self.apply(tree, results, i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 968,
     "status": "ok",
     "timestamp": 1528060794097,
     "user": {
      "displayName": "Alexander Telfar",
      "photoUrl": "//lh4.googleusercontent.com/-bOBnzCbRWgs/AAAAAAAAAAI/AAAAAAAAABw/Sd6a7MwcUDU/s50-c-k-no/photo.jpg",
      "userId": "112995735588747661471"
     },
     "user_tz": -720
    },
    "id": "gWvMnNwPvr1F",
    "outputId": "b5671bde-1c65-4d4f-a914-f31b40cffddd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=395, shape=(1, 50), dtype=float32, numpy=\n",
       "array([[-0.03000259,  0.12397584,  0.07279226, -0.2090192 ,  0.12104005,\n",
       "        -0.18710051, -0.10114643,  0.08847106,  0.23247388,  0.01880257,\n",
       "         0.16483982, -0.03280551, -0.14048365, -0.00199388,  0.07384284,\n",
       "        -0.06964146,  0.0094379 , -0.1465935 ,  0.21219827, -0.13372083,\n",
       "        -0.12857585,  0.06898802,  0.21416542,  0.08968278, -0.18789943,\n",
       "        -0.10467124, -0.02284116, -0.1230051 ,  0.0354168 , -0.05308964,\n",
       "         0.16737577, -0.01140991,  0.19947988, -0.04662628, -0.22023317,\n",
       "        -0.15620331, -0.20942825,  0.24156609, -0.17697154,  0.04958358,\n",
       "        -0.24008581, -0.09461536, -0.11807208, -0.199788  , -0.04693555,\n",
       "         0.01570038, -0.21335697, -0.17780055, -0.20999888, -0.07432975]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treenn = TreeNN(Sat3Cell(d_world, n_ops, d_embed), prop_parser)\n",
    "treenn(w, '((m>m)&(((m>m)>(m>m))&((m>m)>(m|m))))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Mu58VBNtly-O"
   },
   "outputs": [],
   "source": [
    "class PossibleWorlds():\n",
    "  \"\"\"\n",
    "  A NN designed specifically for predicting entailment.\n",
    "  \"\"\"\n",
    "  def __init__(self, encoder, num_units, n_worlds, d_world):\n",
    "    self.encoder = encoder\n",
    "    self.n_worlds = n_worlds\n",
    "    self.worlds = tf.get_variable(shape=(n_worlds, d_world), dtype=tf.float32, name='worlds')\n",
    "    \n",
    "    self.dense = tf.keras.layers.Dense(num_units)\n",
    "  \n",
    "  \n",
    "  def inner(self, a, b):\n",
    "    \"\"\"\n",
    "    Convolve over possible worlds.\n",
    "    For each random direction, do !??!\n",
    "    \n",
    "    \"\"\"\n",
    "    p = tf.constant(1.0, dtype=tf.float32) \n",
    "    for i in range(self.n_worlds):\n",
    "      \n",
    "      x = tf.concat([self.encoder(self.worlds[i:i+1], a), \n",
    "                     self.encoder(self.worlds[i:i+1], b)], axis=1)\n",
    "      p *= self.dense(x)  # in the paper this isnt actually a dense layer....\n",
    "      \n",
    "    return p\n",
    "  \n",
    "  def __call__(self, A, B):\n",
    "    \"\"\"\n",
    "    For each element of a batch.\n",
    "    \"\"\"\n",
    "    return tf.concat([self.inner(a, b) for a, b in zip(A, B)], axis=0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "h3ZtKa-gu-re"
   },
   "outputs": [],
   "source": [
    "possibleworldsnet = PossibleWorlds(\n",
    "    encoder=TreeNN(Sat3Cell(d_world, n_ops, d_embed), prop_parser),\n",
    "    num_units=1,\n",
    "    n_worlds=n_worlds, \n",
    "    d_world=d_world\n",
    ")\n",
    "\n",
    "variables = (possibleworldsnet.dense.variables + \n",
    "             [possibleworldsnet.encoder.cell.b4,\n",
    "             possibleworldsnet.encoder.cell.op_embeddings, \n",
    "             possibleworldsnet.encoder.cell.W4])\n",
    "\n",
    "opt = tf.train.AdamOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vdu18mMYvzzp"
   },
   "outputs": [],
   "source": [
    "def gradients(A, B, E):\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    y = possibleworldsnet(A, B)\n",
    "    loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.constant(E, dtype=tf.float32, shape=(batch_size, 1)),\n",
    "                                          logits=y)\n",
    "    \n",
    "    step = tf.train.get_or_create_global_step().numpy()\n",
    "    print('\\rstep: {} loss {}'.format(step, tf.reduce_mean(loss)), end='', flush=True)\n",
    "    \n",
    "  return tape.gradient(loss, variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aka3mR6M5uoD",
    "outputId": "ece98d6a-52dc-439e-f821-9b6baf39fbe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 67 loss 0.6931471824645996"
     ]
    }
   ],
   "source": [
    "for A, B, E in batch_data(data, batch_size):\n",
    "  gnvs = zip(gradients(A, B, E), variables)\n",
    "  opt.apply_gradients(gnvs, global_step=tf.train.get_or_create_global_step())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rXB2xksk9nJo"
   },
   "source": [
    "Argh. It is soo slow... A problem for another day."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "possibleworldnet.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
